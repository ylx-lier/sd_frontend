import gradio as gr
import torch
from diffusers import StableDiffusionPipeline, StableDiffusionControlNetPipeline, ControlNetModel
from diffusers import StableDiffusionImg2ImgPipeline, DPMSolverMultistepScheduler
import cv2
import numpy as np
from PIL import Image
import warnings
import requests
import io
import base64
import subprocess
import os
from datetime import datetime

warnings.filterwarnings("ignore")

# å…¨å±€å˜é‡å­˜å‚¨ç®¡é“
pipe = None
controlnet_pipe = None
img2img_pipe = None
device = "cuda" if torch.cuda.is_available() else "cpu"
current_model = "runwayml/stable-diffusion-v1-5"
current_controlnet = None

# è¿è¡Œæ¨¡å¼é€‰æ‹©
RUN_MODE = "api"  # "local" æˆ– "api"
HF_API_TOKEN = None  # åœ¨è¿™é‡Œè®¾ç½®æ‚¨çš„ Hugging Face API Token

# ä»£ç†è®¾ç½® (ç”¨äºè§£å†³ç½‘ç»œè¿æ¥é—®é¢˜)
PROXY_CONFIG = {
    "enabled": False,
    "http": None,
    "https": None
}

def update_proxy_config(enabled, http_proxy, https_proxy):
    """æ›´æ–°ä»£ç†é…ç½®"""
    global PROXY_CONFIG
    PROXY_CONFIG["enabled"] = enabled
    PROXY_CONFIG["http"] = http_proxy if http_proxy.strip() else None
    PROXY_CONFIG["https"] = https_proxy if https_proxy.strip() else None
    
    if enabled and (PROXY_CONFIG["http"] or PROXY_CONFIG["https"]):
        return f"âœ… ä»£ç†å·²å¯ç”¨: HTTP={PROXY_CONFIG['http'] or 'None'}, HTTPS={PROXY_CONFIG['https'] or 'None'}"
    else:
        return "âŒ ä»£ç†å·²ç¦ç”¨"

def auto_push_to_github():
    """è‡ªåŠ¨æ¨é€åˆ° GitHub"""
    try:
        print("ğŸš€ å¼€å§‹è‡ªåŠ¨æ¨é€åˆ° GitHub...")
        
        # æ£€æŸ¥æ˜¯å¦åœ¨ git ä»“åº“ä¸­
        result = subprocess.run("git status", shell=True, capture_output=True, text=True)
        if result.returncode != 0:
            return "âŒ å½“å‰ç›®å½•ä¸æ˜¯ git ä»“åº“æˆ– git æœªå®‰è£…"
        
        # æ·»åŠ æ‰€æœ‰æ›´æ”¹çš„æ–‡ä»¶
        result = subprocess.run("git add .", shell=True, capture_output=True, text=True)
        if result.returncode != 0:
            return f"âŒ æ·»åŠ æ–‡ä»¶å¤±è´¥: {result.stderr}"
        
        # æ£€æŸ¥æ˜¯å¦æœ‰æ›´æ”¹éœ€è¦æäº¤
        result = subprocess.run("git diff --staged --quiet", shell=True, capture_output=True, text=True)
        if result.returncode == 0:  # å¦‚æœå‘½ä»¤æˆåŠŸï¼Œè¯´æ˜æ²¡æœ‰æ›´æ”¹
            return "âœ… æ²¡æœ‰æ–°çš„æ›´æ”¹éœ€è¦æäº¤"
        
        # ç”Ÿæˆæ—¶é—´æˆ³
        timestamp = datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        
        # å‡†å¤‡æäº¤ä¿¡æ¯
        commit_message = f"Auto update: {timestamp} - åŠŸèƒ½æ›´æ–°å’Œä¼˜åŒ–"
        
        # æäº¤æ›´æ”¹
        result = subprocess.run(f'git commit -m "{commit_message}"', shell=True, capture_output=True, text=True)
        if result.returncode != 0:
            return f"âŒ æäº¤å¤±è´¥: {result.stderr}"
        
        # æ¨é€åˆ°è¿œç¨‹ä»“åº“
        result = subprocess.run("git push origin main", shell=True, capture_output=True, text=True)
        if result.returncode != 0:
            return f"âŒ æ¨é€å¤±è´¥: {result.stderr}\nğŸ’¡ è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ– GitHub æƒé™"
        
        # è·å–ä»“åº“ URL
        result = subprocess.run("git remote get-url origin", shell=True, capture_output=True, text=True)
        repo_url = result.stdout.strip() if result.returncode == 0 else "æœªçŸ¥"
        
        return f"âœ… æˆåŠŸæ¨é€åˆ° GitHub!\nğŸ”— ä»“åº“: {repo_url}\nâ° æ—¶é—´: {timestamp}"
        
    except Exception as e:
        return f"âŒ æ¨é€è¿‡ç¨‹ä¸­å‘ç”Ÿé”™è¯¯: {str(e)}"

# APIæ¨¡å¼ä¸‹çš„æ¨ç†ç«¯ç‚¹
API_ENDPOINTS = {
    "runwayml/stable-diffusion-v1-5": "https://api-inference.huggingface.co/models/runwayml/stable-diffusion-v1-5",
    "stabilityai/stable-diffusion-2-1": "https://api-inference.huggingface.co/models/stabilityai/stable-diffusion-2-1",
    "dreamlike-art/dreamlike-diffusion-1.0": "https://api-inference.huggingface.co/models/dreamlike-art/dreamlike-diffusion-1.0",
    "prompthero/openjourney": "https://api-inference.huggingface.co/models/prompthero/openjourney",
}

# ControlNet API endpoints
CONTROLNET_API_ENDPOINTS = {
    "canny": "https://api-inference.huggingface.co/models/lllyasviel/sd-controlnet-canny",
    "scribble": "https://api-inference.huggingface.co/models/lllyasviel/sd-controlnet-scribble", 
    "depth": "https://api-inference.huggingface.co/models/lllyasviel/sd-controlnet-depth"
}

# ControlNet ç±»å‹é€‰é¡¹
CONTROLNET_TYPES = {
    "canny": {
        "name": "Cannyè¾¹ç¼˜æ£€æµ‹",
        "model_id": "lllyasviel/sd-controlnet-canny",
        "description": "æ£€æµ‹å›¾åƒè¾¹ç¼˜è½®å»“ï¼Œä¿æŒç‰©ä½“å½¢çŠ¶"
    },
    "scribble": {
        "name": "Scribbleæ¶‚é¸¦æ§åˆ¶",
        "model_id": "lllyasviel/sd-controlnet-scribble", 
        "description": "åŸºäºæ‰‹ç»˜æ¶‚é¸¦æˆ–ç®€ç¬”ç”»ç”Ÿæˆå›¾åƒ"
    },
    "depth": {
        "name": "Depthæ·±åº¦æ§åˆ¶",
        "model_id": "lllyasviel/sd-controlnet-depth",
        "description": "åŸºäºæ·±åº¦å›¾æ§åˆ¶ç©ºé—´ç»“æ„å’Œå±‚æ¬¡"
    }
}

# é¢„å®šä¹‰æ¨¡å‹åˆ—è¡¨
MODELS = {
    "runwayml/stable-diffusion-v1-5": "Stable Diffusion v1.5 (æ ‡å‡†æ¨¡å‹)",
    "stabilityai/stable-diffusion-2-1": "Stable Diffusion v2.1 (æ›´é«˜è´¨é‡)",
    "dreamlike-art/dreamlike-diffusion-1.0": "Dreamlike Diffusion (è‰ºæœ¯é£æ ¼)",
    "prompthero/openjourney": "OpenJourney (å¤šæ ·åŒ–é£æ ¼)",
    "wavymulder/Analog-Diffusion": "Analog Diffusion (èƒ¶ç‰‡é£æ ¼)",
    "22h/vintedois-diffusion-v0-1": "VintedoisDiffusion (å¤å¤é£æ ¼)",
    "nitrosocke/Arcane-Diffusion": "Arcane Diffusion (åŠ¨ç”»é£æ ¼)",
    "hakurei/waifu-diffusion": "Waifu Diffusion (åŠ¨æ¼«é£æ ¼)"
}

# Prompt è¾…åŠ©è¯æ¡
PROMPT_CATEGORIES = {
    "è´¨é‡å¢å¼º": [
        "masterpiece", "best quality", "ultra detailed", "extremely detailed", 
        "high resolution", "8k", "4k", "highly detailed", "sharp focus",
        "professional photography", "award winning", "cinematic lighting"
    ],
    "è‰ºæœ¯é£æ ¼": [
        "oil painting", "watercolor", "digital art", "concept art", "illustration",
        "anime style", "cartoon style", "realistic", "photorealistic", "hyperrealistic",
        "art nouveau", "baroque", "impressionist", "surreal", "abstract"
    ],
    "å…‰ç…§æ•ˆæœ": [
        "soft lighting", "dramatic lighting", "cinematic lighting", "golden hour",
        "studio lighting", "natural lighting", "ambient lighting", "rim lighting",
        "volumetric lighting", "god rays", "neon lighting", "sunset", "sunrise"
    ],
    "æ„å›¾è§†è§’": [
        "close-up", "portrait", "full body", "wide shot", "aerial view",
        "bird's eye view", "low angle", "high angle", "profile view",
        "three-quarter view", "dynamic pose", "action shot"
    ],
    "æƒ…ç»ªæ°›å›´": [
        "peaceful", "dramatic", "mysterious", "romantic", "epic", "serene",
        "energetic", "melancholic", "cheerful", "dark", "bright", "cozy",
        "majestic", "elegant", "powerful", "gentle"
    ],
    "ç¯å¢ƒåœºæ™¯": [
        "forest", "mountain", "ocean", "city", "countryside", "desert",
        "fantasy world", "sci-fi", "medieval", "modern", "futuristic",
        "indoor", "outdoor", "studio", "landscape", "urban", "nature"
    ],
    "è‰²å½©é£æ ¼": [
        "vibrant colors", "muted colors", "monochrome", "black and white",
        "warm colors", "cool colors", "pastel colors", "neon colors",
        "earth tones", "jewel tones", "vintage colors", "saturated"
    ]
}

# è´Ÿé¢æç¤ºè¯è¾…åŠ©è¯æ¡
NEGATIVE_PROMPT_CATEGORIES = {
    "ç”»è´¨é—®é¢˜": [
        "blurry", "low quality", "bad quality", "worst quality", "poor quality",
        "pixelated", "jpeg artifacts", "compression artifacts", "distorted",
        "low resolution", "grainy", "noisy", "oversaturated", "undersaturated"
    ],
    "è§£å‰–é”™è¯¯": [
        "bad anatomy", "bad hands", "bad fingers", "extra fingers", "missing fingers",
        "extra limbs", "missing limbs", "deformed", "mutated", "disfigured",
        "malformed", "extra arms", "extra legs", "fused fingers", "too many fingers"
    ],
    "é¢éƒ¨é—®é¢˜": [
        "bad face", "ugly face", "distorted face", "asymmetrical face",
        "bad eyes", "cross-eyed", "extra eyes", "missing eyes", "bad mouth",
        "bad teeth", "crooked teeth", "bad nose", "asymmetrical features"
    ],
    "è‰ºæœ¯é£æ ¼": [
        "cartoon", "anime", "manga", "3d render", "painting", "sketch",
        "watercolor", "oil painting", "digital art", "illustration",
        "abstract", "surreal", "unrealistic", "stylized"
    ],
    "æŠ€æœ¯é—®é¢˜": [
        "watermark", "signature", "text", "logo", "copyright", "username",
        "frame", "border", "cropped", "cut off", "out of frame",
        "duplicate", "error", "glitch", "artifact"
    ],
    "å…‰ç…§é—®é¢˜": [
        "bad lighting", "harsh lighting", "overexposed", "underexposed",
        "too dark", "too bright", "uneven lighting", "poor contrast",
        "washed out", "flat lighting", "artificial lighting"
    ],
    "æ„å›¾é—®é¢˜": [
        "bad composition", "off-center", "tilted", "crooked", "unbalanced",
        "cluttered", "messy", "chaotic", "poor framing", "bad angle",
        "awkward pose", "stiff pose", "unnatural pose"
    ]
}

def load_models(run_mode, selected_model, controlnet_type="canny", api_token=""):
    """åŠ è½½æ¨¡å‹ç®¡é“"""
    global pipe, controlnet_pipe, img2img_pipe, current_model, current_controlnet, RUN_MODE, HF_API_TOKEN
    
    if not selected_model:
        return "âŒ è¯·é€‰æ‹©ä¸€ä¸ªæ¨¡å‹"
    
    # æ›´æ–°å…¨å±€é…ç½®
    RUN_MODE = run_mode
    current_model = selected_model
    if api_token.strip():
        HF_API_TOKEN = api_token.strip()
    model_name = MODELS.get(selected_model, selected_model)
    
    if run_mode == "api":
        # APIæ¨¡å¼ - ä¸ä¸‹è½½æ¨¡å‹
        if selected_model not in API_ENDPOINTS:
            return f"âŒ æ¨¡å‹ {model_name} ä¸æ”¯æŒAPIæ¨¡å¼\nğŸ’¡ è¯·é€‰æ‹©æ”¯æŒAPIçš„æ¨¡å‹æˆ–åˆ‡æ¢åˆ°æœ¬åœ°æ¨¡å¼"
        
        # æ¨¡æ‹ŸåŠ è½½æˆåŠŸ
        pipe = "api_mode"
        img2img_pipe = "api_mode" 
        controlnet_pipe = "api_mode"
        current_controlnet = controlnet_type
        
        api_status = "ğŸŒ APIæ¨¡å¼ - æ— éœ€ä¸‹è½½æ¨¡å‹" if not HF_API_TOKEN else "ğŸŒ APIæ¨¡å¼ - ä½¿ç”¨è®¤è¯Token"
        return f"âœ… APIæ¨¡å¼é…ç½®æˆåŠŸï¼\nğŸ“¦ å½“å‰æ¨¡å‹: {model_name}\nğŸ¯ æ¨¡å‹ID: {selected_model}\nğŸ® ControlNet: {CONTROLNET_TYPES[controlnet_type]['name']}\n{api_status}\nğŸ’¾ å­˜å‚¨ç©ºé—´å ç”¨: 0 GB"
    
    else:
        # æœ¬åœ°æ¨¡å¼ - ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°
        try:
            # åŸºç¡€æ–‡ç”Ÿå›¾ç®¡é“
            pipe = StableDiffusionPipeline.from_pretrained(
                selected_model,
                torch_dtype=torch.float16 if device == "cuda" else torch.float32,
                safety_checker=None,
                requires_safety_checker=False
            )
            pipe = pipe.to(device)
            pipe.scheduler = DPMSolverMultistepScheduler.from_config(pipe.scheduler.config)
            
            # ä¼ ç»Ÿå›¾ç”Ÿå›¾ç®¡é“
            img2img_pipe = StableDiffusionImg2ImgPipeline.from_pretrained(
                selected_model,
                torch_dtype=torch.float16 if device == "cuda" else torch.float32,
                safety_checker=None,
                requires_safety_checker=False
            )
            img2img_pipe = img2img_pipe.to(device)
            img2img_pipe.scheduler = DPMSolverMultistepScheduler.from_config(img2img_pipe.scheduler.config)
            
            # ControlNet ç®¡é“
            try:
                current_controlnet = controlnet_type
                controlnet_info = CONTROLNET_TYPES[controlnet_type]
                
                controlnet = ControlNetModel.from_pretrained(
                    controlnet_info["model_id"],
                    torch_dtype=torch.float16 if device == "cuda" else torch.float32
                )
                controlnet_pipe = StableDiffusionControlNetPipeline.from_pretrained(
                    selected_model,
                    controlnet=controlnet,
                    torch_dtype=torch.float16 if device == "cuda" else torch.float32,
                    safety_checker=None,
                    requires_safety_checker=False
                )
                controlnet_pipe = controlnet_pipe.to(device)
                controlnet_pipe.scheduler = DPMSolverMultistepScheduler.from_config(controlnet_pipe.scheduler.config)
                return f"âœ… æœ¬åœ°æ¨¡å¼æ‰€æœ‰æ¨¡å‹åŠ è½½æˆåŠŸï¼\nğŸ“¦ å½“å‰æ¨¡å‹: {model_name}\nğŸ¯ æ¨¡å‹ID: {selected_model}\nğŸ® ControlNet: {controlnet_info['name']}\nğŸ’¾ é¢„è®¡å­˜å‚¨å ç”¨: ~6-10 GB"
            except Exception as controlnet_error:
                return f"âœ… æœ¬åœ°æ¨¡å¼åŸºç¡€æ¨¡å‹åŠ è½½æˆåŠŸï¼\nğŸ“¦ å½“å‰æ¨¡å‹: {model_name}\nğŸ¯ æ¨¡å‹ID: {selected_model}\nâš ï¸ ControlNetåŠ è½½å¤±è´¥: {str(controlnet_error)}\nğŸ’¡ æ–‡ç”Ÿå›¾å’Œä¼ ç»Ÿå›¾ç”Ÿå›¾åŠŸèƒ½å¯æ­£å¸¸ä½¿ç”¨\nğŸ’¾ é¢„è®¡å­˜å‚¨å ç”¨: ~4-7 GB"
            
        except Exception as e:
            return f"âŒ æœ¬åœ°æ¨¡å¼åŠ è½½å¤±è´¥: {str(e)}\nğŸ’¡ å»ºè®®å°è¯•APIæ¨¡å¼ä»¥é¿å…å­˜å‚¨ç©ºé—´é—®é¢˜"

def generate_image(prompt, negative_prompt, num_steps, guidance_scale, width, height, seed):
    """åŸºç¡€æ–‡ç”Ÿå›¾åŠŸèƒ½"""
    global pipe, current_model, RUN_MODE
    
    if pipe is None:
        return None, "Please load the model first"
    
    if RUN_MODE == "api":
        # APIæ¨¡å¼
        try:
            image, status = generate_image_api(prompt, negative_prompt, current_model)
            return image, status
        except Exception as e:
            return None, f"âŒ APIç”Ÿæˆå¤±è´¥: {str(e)}"
    
    else:
        # æœ¬åœ°æ¨¡å¼
        try:
            # è®¾ç½®éšæœºç§å­
            if seed != -1:
                generator = torch.Generator(device=device).manual_seed(seed)
            else:
                generator = None
                
            # ç”Ÿæˆå›¾åƒ
            with torch.autocast(device):
                result = pipe(
                    prompt=prompt,
                    negative_prompt=negative_prompt if negative_prompt else None,
                    num_inference_steps=num_steps,
                    guidance_scale=guidance_scale,
                    width=width,
                    height=height,
                    generator=generator
                )
            
            image = result.images[0]
            return image, "âœ… æœ¬åœ°å›¾åƒç”ŸæˆæˆåŠŸï¼"
            
        except Exception as e:
            return None, f"âŒ æœ¬åœ°ç”Ÿæˆå¤±è´¥: {str(e)}"

def preprocess_canny(image, low_threshold=100, high_threshold=200):
    """é¢„å¤„ç†å›¾åƒä¸ºCannyè¾¹ç¼˜"""
    image = np.array(image)
    canny = cv2.Canny(image, low_threshold, high_threshold)
    canny_image = canny[:, :, None]
    canny_image = np.concatenate([canny_image, canny_image, canny_image], axis=2)
    return Image.fromarray(canny_image)

def preprocess_scribble(image):
    """é¢„å¤„ç†å›¾åƒä¸ºæ¶‚é¸¦é£æ ¼ï¼ˆç®€åŒ–è¾¹ç¼˜ï¼‰"""
    image = np.array(image)
    # è½¬æ¢ä¸ºç°åº¦å›¾
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    # ä½¿ç”¨è¾¹ç¼˜æ£€æµ‹ä½†å‚æ•°æ›´å®½æ¾ï¼Œæ¨¡æ‹Ÿæ¶‚é¸¦æ•ˆæœ
    edges = cv2.Canny(gray, 50, 150)
    # è†¨èƒ€æ“ä½œä½¿çº¿æ¡æ›´ç²—ï¼Œæ›´åƒæ¶‚é¸¦
    kernel = np.ones((3,3), np.uint8)
    edges = cv2.dilate(edges, kernel, iterations=1)
    # è½¬æ¢å›RGB
    scribble_image = edges[:, :, None]
    scribble_image = np.concatenate([scribble_image, scribble_image, scribble_image], axis=2)
    return Image.fromarray(scribble_image)

def preprocess_depth(image):
    """é¢„å¤„ç†å›¾åƒä¸ºæ·±åº¦å›¾ï¼ˆä½¿ç”¨ç®€å•çš„æ·±åº¦ä¼°è®¡ï¼‰"""
    image = np.array(image)
    # è½¬æ¢ä¸ºç°åº¦å›¾ä½œä¸ºç®€å•çš„æ·±åº¦ä¼°è®¡
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    # åº”ç”¨é«˜æ–¯æ¨¡ç³Šæ¥æ¨¡æ‹Ÿæ·±åº¦æ„Ÿ
    depth = cv2.GaussianBlur(gray, (5, 5), 0)
    # å¢å¼ºå¯¹æ¯”åº¦
    depth = cv2.equalizeHist(depth)
    # è½¬æ¢å›RGB
    depth_image = depth[:, :, None]
    depth_image = np.concatenate([depth_image, depth_image, depth_image], axis=2)
    return Image.fromarray(depth_image)

def preprocess_control_image(image, control_type):
    """æ ¹æ®æ§åˆ¶ç±»å‹é¢„å¤„ç†å›¾åƒ"""
    if control_type == "canny":
        return preprocess_canny(image)
    elif control_type == "scribble":
        return preprocess_scribble(image)
    elif control_type == "depth":
        return preprocess_depth(image)
    else:
        return preprocess_canny(image)  # é»˜è®¤ä½¿ç”¨canny

def generate_controlnet_image(prompt, negative_prompt, control_image, control_type, num_steps, guidance_scale, controlnet_conditioning_scale, width, height, seed):
    """ControlNetå›¾åƒå¼•å¯¼ç”Ÿæˆ"""
    global controlnet_pipe, current_controlnet, RUN_MODE
    
    if controlnet_pipe is None:
        return None, None, "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹"
    
    if control_image is None:
        return None, None, "âŒ è¯·ä¸Šä¼ æ§åˆ¶å›¾åƒ"
    
    # æ£€æŸ¥å½“å‰åŠ è½½çš„ControlNetç±»å‹æ˜¯å¦åŒ¹é…
    if current_controlnet != control_type:
        return None, None, f"âŒ å½“å‰åŠ è½½çš„æ˜¯ {CONTROLNET_TYPES[current_controlnet]['name']}ï¼Œè¯·é‡æ–°åŠ è½½æ¨¡å‹é€‰æ‹© {CONTROLNET_TYPES[control_type]['name']}"
    
    # é¢„å¤„ç†æ§åˆ¶å›¾åƒ
    processed_image = preprocess_control_image(control_image, control_type)
    
    if RUN_MODE == "api":
        # APIæ¨¡å¼
        try:
            image, status = generate_controlnet_image_api(prompt, negative_prompt, processed_image, control_type)
            return image, processed_image, status
        except Exception as e:
            return None, processed_image, f"âŒ APIç”Ÿæˆå¤±è´¥: {str(e)}"
    
    else:
        # æœ¬åœ°æ¨¡å¼
        try:
            # è®¾ç½®éšæœºç§å­
            if seed != -1:
                generator = torch.Generator(device=device).manual_seed(seed)
            else:
                generator = None
                
            # ç”Ÿæˆå›¾åƒ
            with torch.autocast(device):
                result = controlnet_pipe(
                    prompt=prompt,
                    negative_prompt=negative_prompt if negative_prompt else None,
                    image=processed_image,
                    num_inference_steps=num_steps,
                    guidance_scale=guidance_scale,
                    controlnet_conditioning_scale=controlnet_conditioning_scale,
                    width=width,
                    height=height,
                    generator=generator
                )
            
            image = result.images[0]
            control_type_name = CONTROLNET_TYPES[control_type]['name']
            return image, processed_image, f"âœ… {control_type_name}å›¾åƒç”ŸæˆæˆåŠŸï¼"
            
        except Exception as e:
            return None, processed_image, f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"

def generate_img2img(prompt, negative_prompt, input_image, strength, num_steps, guidance_scale, width, height, seed):
    """ä¼ ç»Ÿå›¾ç”Ÿå›¾åŠŸèƒ½"""
    global img2img_pipe, RUN_MODE
    
    if img2img_pipe is None:
        return None, "âŒ è¯·å…ˆåŠ è½½æ¨¡å‹"
    
    if input_image is None:
        return None, "âŒ è¯·ä¸Šä¼ è¾“å…¥å›¾åƒ"
    
    # è°ƒæ•´å›¾åƒå¤§å°
    input_image = input_image.resize((width, height))
    
    if RUN_MODE == "api":
        # APIæ¨¡å¼
        try:
            image, status = generate_img2img_api(prompt, negative_prompt, input_image, strength)
            return image, status
        except Exception as e:
            return None, f"âŒ APIç”Ÿæˆå¤±è´¥: {str(e)}"
    
    else:
        # æœ¬åœ°æ¨¡å¼
        try:
            # è®¾ç½®éšæœºç§å­
            if seed != -1:
                generator = torch.Generator(device=device).manual_seed(seed)
            else:
                generator = None
                
            # ç”Ÿæˆå›¾åƒ
            with torch.autocast(device):
                result = img2img_pipe(
                    prompt=prompt,
                    negative_prompt=negative_prompt if negative_prompt else None,
                    image=input_image,
                    strength=strength,
                    num_inference_steps=num_steps,
                    guidance_scale=guidance_scale,
                    generator=generator
                )
            
            image = result.images[0]
            return image, "âœ… ä¼ ç»Ÿå›¾ç”Ÿå›¾æˆåŠŸï¼"
            
        except Exception as e:
            return None, f"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}"

def add_prompt_tags(current_prompt, selected_tags):
    """æ·»åŠ é€‰ä¸­çš„æ ‡ç­¾åˆ°promptä¸­"""
    if not selected_tags:
        return current_prompt
    
    # å°†é€‰ä¸­çš„æ ‡ç­¾åˆå¹¶
    new_tags = ", ".join(selected_tags)
    
    if current_prompt:
        # å¦‚æœå·²æœ‰promptï¼Œåˆ™æ·»åŠ åˆ°æœ«å°¾
        return f"{current_prompt}, {new_tags}"
    else:
        # å¦‚æœæ²¡æœ‰promptï¼Œç›´æ¥ä½¿ç”¨æ ‡ç­¾
        return new_tags

def get_current_model_info():
    """è·å–å½“å‰æ¨¡å‹ä¿¡æ¯"""
    global current_model
    if current_model:
        model_name = MODELS.get(current_model, current_model)
        return f"ğŸ“¦ å½“å‰æ¨¡å‹: {model_name}"
    else:
        return "âŒ æœªåŠ è½½æ¨¡å‹"

# åˆ›å»ºGradioç•Œé¢
def create_interface():
    with gr.Blocks(title="ğŸ¨ AI å›¾åƒç”Ÿæˆå™¨", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸ¨ AI å›¾åƒç”Ÿæˆå™¨ Pro
        
        æ”¯æŒå¤šç§æ¨¡å‹å’Œä¸‰ç§ç”Ÿæˆæ¨¡å¼ï¼š
        - **ğŸ“ æ–‡ç”Ÿå›¾æ¨¡å¼**ï¼šçº¯æ–‡æœ¬æè¿°ç”Ÿæˆå›¾åƒ
        - **ğŸ”„ ä¼ ç»Ÿå›¾ç”Ÿå›¾**ï¼šå›¾åƒé£æ ¼è½¬æ¢
        - **ğŸ–¼ï¸ ControlNetæ¨¡å¼**ï¼šç²¾ç¡®ç»“æ„æ§åˆ¶çš„å›¾åƒç”Ÿæˆ
        
        > åŸºäº Stable Diffusion ç³»åˆ—æ¨¡å‹ + ControlNet
        """)
        
        # æ¨¡å¼è¯´æ˜ä¿¡æ¯é¢æ¿
        gr.Markdown("""
        ### ğŸš€ è¿è¡Œæ¨¡å¼è¯´æ˜
        - **ğŸŒ APIæ¨¡å¼ (æ¨è)**: é€šè¿‡ Hugging Face API åœ¨çº¿ç”Ÿæˆï¼Œ**æ— éœ€ä¸‹è½½ä»»ä½•æ¨¡å‹**ï¼ŒèŠ‚çœ 4-10GB å­˜å‚¨ç©ºé—´ï¼
        - **ğŸ’» æœ¬åœ°æ¨¡å¼**: ä¸‹è½½æ¨¡å‹åˆ°æœ¬åœ°è¿è¡Œï¼Œéœ€è¦ 4-10GB å­˜å‚¨ç©ºé—´ï¼Œä½†è¿è¡Œé€Ÿåº¦æ›´å¿«ï¼Œæ”¯æŒæ›´å¤šè‡ªå®šä¹‰å‚æ•°
        - **ğŸ”‘ API Token**: APIæ¨¡å¼éœ€è¦ [Hugging Face Token](https://huggingface.co/settings/tokens) (å…è´¹è´¦æˆ·å³å¯)
        """)
        
        # æ¨¡å‹é€‰æ‹©å’ŒåŠ è½½åŒºåŸŸ
        with gr.Row():
            with gr.Column(scale=3):
                # è¿è¡Œæ¨¡å¼é€‰æ‹©
                run_mode_radio = gr.Radio(
                    choices=[
                        ("ğŸŒ APIæ¨¡å¼ (æ¨è) - æ— éœ€ä¸‹è½½ï¼ŒèŠ‚çœå­˜å‚¨ç©ºé—´", "api"),
                        ("ğŸ’» æœ¬åœ°æ¨¡å¼ - ä¸‹è½½åˆ°æœ¬åœ°ï¼Œéœ€è¦å¤§é‡å­˜å‚¨ç©ºé—´", "local")
                    ],
                    value="api",
                    label="âš™ï¸ è¿è¡Œæ¨¡å¼",
                    info="APIæ¨¡å¼é€šè¿‡ç½‘ç»œè°ƒç”¨ï¼Œæœ¬åœ°æ¨¡å¼éœ€è¦ä¸‹è½½4-10GBæ¨¡å‹æ–‡ä»¶"
                )
                
                model_dropdown = gr.Dropdown(
                    choices=list(MODELS.keys()),
                    value="runwayml/stable-diffusion-v1-5",
                    label="ğŸ¤– é€‰æ‹©åŸºç¡€æ¨¡å‹",
                    info="é€‰æ‹©ä¸åŒçš„é¢„è®­ç»ƒæ¨¡å‹ä»¥è·å¾—ä¸åŒçš„è‰ºæœ¯é£æ ¼"
                )
                controlnet_dropdown = gr.Dropdown(
                    choices=[(f"{info['name']} - {info['description']}", key) for key, info in CONTROLNET_TYPES.items()],
                    value="canny",
                    label="ğŸ® é€‰æ‹©ControlNetç±»å‹",
                    info="é€‰æ‹©ä¸åŒçš„æ§åˆ¶æ–¹å¼"
                )
                
                # API Token è®¾ç½®
                with gr.Accordion("ğŸ”‘ APIè®¾ç½® (APIæ¨¡å¼å¿…çœ‹)", open=True):
                    gr.Markdown("""
                    **ğŸ¯ è·å–å…è´¹API Tokenï¼š**
                    1. è®¿é—® [Hugging Face](https://huggingface.co/settings/tokens)
                    2. åˆ›å»ºæ–°Token (Readæƒé™å³å¯)
                    3. å¤åˆ¶å¹¶ç²˜è´´åˆ°ä¸‹æ–¹è¾“å…¥æ¡†
                    
                    **ğŸ’¡ æç¤ºï¼š** å…è´¹è´¦æˆ·æ¯æœˆæœ‰ä¸€å®šè°ƒç”¨é™åˆ¶ï¼Œä»˜è´¹è´¦æˆ·æ— é™åˆ¶ä¸”é€Ÿåº¦æ›´å¿«
                    """)
                    api_token_input = gr.Textbox(
                        label="ğŸ”‘ Hugging Face API Token",
                        placeholder="hf_xxxxxxxxxxxxxxxxxxxx (å»ºè®®è®¾ç½®ï¼Œå¦åˆ™å¯èƒ½é‡åˆ°é™æµ)",
                        type="password",
                        info="ç‚¹å‡»ä¸Šæ–¹é“¾æ¥è·å–å…è´¹Tokenï¼Œæå‡APIè°ƒç”¨ç¨³å®šæ€§"
                    )
                
                # ä»£ç†è®¾ç½®
                with gr.Accordion("ğŸŒ ç½‘ç»œä»£ç†è®¾ç½® (è§£å†³è¿æ¥è¶…æ—¶é—®é¢˜)", open=False):
                    gr.Markdown("""
                    **ğŸš¨ å¦‚æœé‡åˆ° "API call timeout" é”™è¯¯ï¼Œè¯·å¯ç”¨ä»£ç†ï¼š**
                    
                    **Clash ä»£ç†è®¾ç½®ï¼š**
                    - HTTPä»£ç†ç«¯å£é€šå¸¸æ˜¯ï¼š`http://127.0.0.1:7890`
                    - HTTPSä»£ç†ç«¯å£é€šå¸¸æ˜¯ï¼š`http://127.0.0.1:7890`
                    - å¦‚æœç«¯å£ä¸åŒï¼Œè¯·æŸ¥çœ‹ Clash çš„ç«¯å£è®¾ç½®
                    
                    **å…¶ä»–ä»£ç†è½¯ä»¶ï¼š**
                    - V2Ray: `http://127.0.0.1:10809`
                    - Shadowsocks: `http://127.0.0.1:1080`
                    - è¯·æ ¹æ®æ‚¨çš„ä»£ç†è½¯ä»¶å®é™…ç«¯å£å¡«å†™
                    """)
                    
                    proxy_enabled = gr.Checkbox(
                        label="å¯ç”¨ä»£ç†",
                        value=False,
                        info="å¦‚æœç½‘ç»œè¿æ¥è¶…æ—¶ï¼Œè¯·å¯ç”¨æ­¤é€‰é¡¹"
                    )
                    
                    with gr.Row():
                        http_proxy_input = gr.Textbox(
                            label="HTTP ä»£ç†",
                            placeholder="http://127.0.0.1:7890",
                            info="å¡«å†™ HTTP ä»£ç†åœ°å€å’Œç«¯å£"
                        )
                        https_proxy_input = gr.Textbox(
                            label="HTTPS ä»£ç†", 
                            placeholder="http://127.0.0.1:7890",
                            info="å¡«å†™ HTTPS ä»£ç†åœ°å€å’Œç«¯å£"
                        )
                    
                    proxy_status = gr.Textbox(
                        label="ä»£ç†çŠ¶æ€",
                        value="âŒ ä»£ç†å·²ç¦ç”¨",
                        interactive=False
                    )
                    
                    test_proxy_btn = gr.Button("ğŸ”— æµ‹è¯•ä»£ç†è¿æ¥", variant="secondary")
                    
                    def test_proxy_connection(enabled, http_proxy, https_proxy):
                        """æµ‹è¯•ä»£ç†è¿æ¥"""
                        if not enabled:
                            return "âŒ ä»£ç†æœªå¯ç”¨ï¼Œæ— æ³•æµ‹è¯•"
                        
                        if not (http_proxy or https_proxy):
                            return "âŒ è¯·å¡«å†™ä»£ç†åœ°å€"
                        
                        proxies = {}
                        if http_proxy:
                            proxies["http"] = http_proxy
                        if https_proxy:
                            proxies["https"] = https_proxy
                        
                        try:
                            # æµ‹è¯•è¿æ¥åˆ° Hugging Face
                            response = requests.get(
                                "https://huggingface.co", 
                                proxies=proxies, 
                                timeout=10
                            )
                            if response.status_code == 200:
                                return "âœ… ä»£ç†è¿æ¥æµ‹è¯•æˆåŠŸï¼"
                            else:
                                return f"âš ï¸ ä»£ç†è¿æ¥æµ‹è¯•å¤±è´¥ï¼ŒçŠ¶æ€ç : {response.status_code}"
                        except Exception as e:
                            return f"âŒ ä»£ç†è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)}"
                    
                    test_proxy_btn.click(
                        test_proxy_connection,
                        inputs=[proxy_enabled, http_proxy_input, https_proxy_input],
                        outputs=[proxy_status]
                    )
                    
                load_btn = gr.Button("ğŸš€ åŠ è½½é€‰ä¸­æ¨¡å‹", variant="primary", size="lg")
            with gr.Column(scale=2):
                current_model_display = gr.Textbox(
                    label="å½“å‰æ¨¡å‹çŠ¶æ€", 
                    value="ğŸ“¦ é»˜è®¤æ¨¡å‹: Stable Diffusion v1.5\nğŸ® é»˜è®¤ControlNet: Cannyè¾¹ç¼˜æ£€æµ‹\nâš™ï¸ é»˜è®¤æ¨¡å¼: APIæ¨¡å¼",
                    interactive=False,
                    lines=3
                )
        
        load_status = gr.Textbox(label="åŠ è½½çŠ¶æ€", value="é€‰æ‹©æ¨¡å‹åç‚¹å‡»åŠ è½½å¼€å§‹ä½¿ç”¨", lines=3)
        
        # GitHub è‡ªåŠ¨æ¨é€åŒºåŸŸ
        with gr.Accordion("ğŸš€ GitHub è‡ªåŠ¨æ¨é€", open=False):
            gr.Markdown("""
            **ğŸ“¦ ä»£ç åŒæ­¥åŠŸèƒ½ï¼š**
            - è‡ªåŠ¨å°†å½“å‰æ‰€æœ‰æ›´æ”¹æ¨é€åˆ° GitHub ä»“åº“
            - åŒ…å«ä»£ç æ›´æ–°ã€æ–°å¢æ–‡ä»¶ã€é…ç½®ä¿®æ”¹ç­‰
            - é€‚åˆå¼€å‘è¿‡ç¨‹ä¸­çš„ç‰ˆæœ¬å¤‡ä»½å’ŒåŒæ­¥
            
            **âš ï¸ æ³¨æ„äº‹é¡¹ï¼š**
            - ç¡®ä¿å·²é…ç½® GitHub è®¿é—®æƒé™
            - å»ºè®®åœ¨é‡è¦åŠŸèƒ½å®Œæˆåä½¿ç”¨
            - æ¨é€å‰ä¼šè‡ªåŠ¨æ·»åŠ æ‰€æœ‰æ›´æ”¹æ–‡ä»¶
            """)
            
            with gr.Row():
                push_to_github_btn = gr.Button("ğŸš€ æ¨é€åˆ° GitHub", variant="primary", size="lg")
                github_status = gr.Textbox(
                    label="æ¨é€çŠ¶æ€",
                    value="ç‚¹å‡»æŒ‰é’®å°†ä»£ç æ¨é€åˆ° GitHub ä»“åº“",
                    interactive=False,
                    lines=2
                )
        
        
        # Prompt è¾…åŠ©é€‰æ‹©å™¨
        with gr.Accordion("ğŸ¯ Prompt è¾…åŠ©é€‰æ‹©å™¨", open=False):
            gr.Markdown("### ğŸ’¡ é€‰æ‹©è¯æ¡å¿«é€Ÿæ„å»ºé«˜è´¨é‡æç¤ºè¯")
            
            # æ­£é¢è¯æ¡
            gr.Markdown("#### âœ¨ æ­£é¢æç¤ºè¯ (Positive Prompt)")
            with gr.Row():
                with gr.Column():
                    quality_tags = gr.CheckboxGroup(
                        choices=PROMPT_CATEGORIES["è´¨é‡å¢å¼º"],
                        label="ğŸŒŸ è´¨é‡å¢å¼º",
                        info="æå‡å›¾åƒè´¨é‡å’Œç»†èŠ‚"
                    )
                    style_tags = gr.CheckboxGroup(
                        choices=PROMPT_CATEGORIES["è‰ºæœ¯é£æ ¼"],
                        label="ğŸ¨ è‰ºæœ¯é£æ ¼",
                        info="é€‰æ‹©è‰ºæœ¯è¡¨ç°å½¢å¼"
                    )
                with gr.Column():
                    lighting_tags = gr.CheckboxGroup(
                        choices=PROMPT_CATEGORIES["å…‰ç…§æ•ˆæœ"],
                        label="ğŸ’¡ å…‰ç…§æ•ˆæœ",
                        info="è®¾ç½®å…‰ç…§å’Œæ°›å›´"
                    )
                    composition_tags = gr.CheckboxGroup(
                        choices=PROMPT_CATEGORIES["æ„å›¾è§†è§’"],
                        label="ğŸ“ æ„å›¾è§†è§’",
                        info="é€‰æ‹©æ‹æ‘„è§’åº¦å’Œæ„å›¾"
                    )
                with gr.Column():
                    mood_tags = gr.CheckboxGroup(
                        choices=PROMPT_CATEGORIES["æƒ…ç»ªæ°›å›´"],
                        label="ğŸ˜Š æƒ…ç»ªæ°›å›´",
                        info="è®¾å®šç”»é¢æƒ…æ„Ÿè‰²è°ƒ"
                    )
                    scene_tags = gr.CheckboxGroup(
                        choices=PROMPT_CATEGORIES["ç¯å¢ƒåœºæ™¯"],
                        label="ğŸŒ ç¯å¢ƒåœºæ™¯",
                        info="é€‰æ‹©èƒŒæ™¯å’Œç¯å¢ƒ"
                    )
                with gr.Column():
                    color_tags = gr.CheckboxGroup(
                        choices=PROMPT_CATEGORIES["è‰²å½©é£æ ¼"],
                        label="ğŸ¨ è‰²å½©é£æ ¼",
                        info="è®¾å®šè‰²å½©ä¸»è°ƒ"
                    )
            
            # è´Ÿé¢è¯æ¡
            gr.Markdown("#### ğŸš« è´Ÿé¢æç¤ºè¯ (Negative Prompt)")
            with gr.Row():
                with gr.Column():
                    neg_quality_tags = gr.CheckboxGroup(
                        choices=NEGATIVE_PROMPT_CATEGORIES["ç”»è´¨é—®é¢˜"],
                        label="ğŸš« ç”»è´¨é—®é¢˜",
                        info="é¿å…ç”»è´¨ç›¸å…³é—®é¢˜"
                    )
                    neg_anatomy_tags = gr.CheckboxGroup(
                        choices=NEGATIVE_PROMPT_CATEGORIES["è§£å‰–é”™è¯¯"],
                        label="ğŸš« è§£å‰–é”™è¯¯",
                        info="é¿å…èº«ä½“ç»“æ„é”™è¯¯"
                    )
                with gr.Column():
                    neg_face_tags = gr.CheckboxGroup(
                        choices=NEGATIVE_PROMPT_CATEGORIES["é¢éƒ¨é—®é¢˜"],
                        label="ğŸš« é¢éƒ¨é—®é¢˜",
                        info="é¿å…é¢éƒ¨ç›¸å…³é—®é¢˜"
                    )
                    neg_style_tags = gr.CheckboxGroup(
                        choices=NEGATIVE_PROMPT_CATEGORIES["è‰ºæœ¯é£æ ¼"],
                        label="ğŸš« é¿å…é£æ ¼",
                        info="æ’é™¤ä¸æƒ³è¦çš„è‰ºæœ¯é£æ ¼"
                    )
                with gr.Column():
                    neg_tech_tags = gr.CheckboxGroup(
                        choices=NEGATIVE_PROMPT_CATEGORIES["æŠ€æœ¯é—®é¢˜"],
                        label="ğŸš« æŠ€æœ¯é—®é¢˜",
                        info="é¿å…æ°´å°ã€è£å‰ªç­‰æŠ€æœ¯é—®é¢˜"
                    )
                    neg_lighting_tags = gr.CheckboxGroup(
                        choices=NEGATIVE_PROMPT_CATEGORIES["å…‰ç…§é—®é¢˜"],
                        label="ğŸš« å…‰ç…§é—®é¢˜",
                        info="é¿å…å…‰ç…§ç›¸å…³é—®é¢˜"
                    )
                with gr.Column():
                    neg_composition_tags = gr.CheckboxGroup(
                        choices=NEGATIVE_PROMPT_CATEGORIES["æ„å›¾é—®é¢˜"],
                        label="ğŸš« æ„å›¾é—®é¢˜",
                        info="é¿å…æ„å›¾ç›¸å…³é—®é¢˜"
                    )
            
            with gr.Row():
                clear_tags_btn = gr.Button("ğŸ—‘ï¸ æ¸…ç©ºæ‰€æœ‰é€‰æ‹©", variant="secondary")
                apply_positive_tags_btn = gr.Button("âœ¨ åº”ç”¨æ­£é¢è¯æ¡åˆ°å½“å‰æ ‡ç­¾é¡µ", variant="primary")
                apply_negative_tags_btn = gr.Button("ğŸš« åº”ç”¨è´Ÿé¢è¯æ¡åˆ°å½“å‰æ ‡ç­¾é¡µ", variant="secondary")
        
        with gr.Tabs() as tabs:
            # Tab 1: åŸºç¡€æ–‡ç”Ÿå›¾
            with gr.TabItem("ğŸ“ æ–‡ç”Ÿå›¾æ¨¡å¼"):
                with gr.Row():
                    with gr.Column(scale=1):
                        with gr.Row():
                            prompt1 = gr.Textbox(
                                label="æç¤ºè¯ (Prompt)",
                                placeholder="æè¿°ä½ æƒ³è¦çš„å›¾åƒï¼Œä¾‹å¦‚ï¼ša beautiful landscape with mountains and lakes, highly detailed, 4k",
                                lines=3,
                                scale=4
                            )
                            with gr.Column(scale=1):
                                apply_positive_to_prompt1 = gr.Button("â• æ­£é¢è¯æ¡", variant="secondary", size="sm")
                                apply_negative_to_prompt1 = gr.Button("â– è´Ÿé¢è¯æ¡", variant="secondary", size="sm")
                        
                        negative_prompt1 = gr.Textbox(
                            label="è´Ÿé¢æç¤ºè¯ (Negative Prompt)",
                            placeholder="ä¸æƒ³è¦çš„å…ƒç´ ï¼Œä¾‹å¦‚ï¼šblurry, low quality, distorted",
                            lines=2
                        )
                        
                        with gr.Row():
                            num_steps1 = gr.Slider(10, 50, value=20, step=1, label="é‡‡æ ·æ­¥æ•°")
                            guidance_scale1 = gr.Slider(1, 20, value=7.5, step=0.5, label="å¼•å¯¼å¼ºåº¦")
                        
                        with gr.Row():
                            width1 = gr.Slider(256, 1024, value=512, step=64, label="å®½åº¦")
                            height1 = gr.Slider(256, 1024, value=512, step=64, label="é«˜åº¦")
                        
                        seed1 = gr.Number(label="éšæœºç§å­ (-1ä¸ºéšæœº)", value=-1)
                        generate_btn1 = gr.Button("ğŸ¨ ç”Ÿæˆå›¾åƒ", variant="primary")
                    
                    with gr.Column(scale=1):
                        output_image1 = gr.Image(label="ç”Ÿæˆçš„å›¾åƒ", type="pil")
                        output_status1 = gr.Textbox(label="ç”ŸæˆçŠ¶æ€")
            
            # Tab 2: ä¼ ç»Ÿå›¾ç”Ÿå›¾
            with gr.TabItem("ğŸ”„ ä¼ ç»Ÿå›¾ç”Ÿå›¾"):
                with gr.Row():
                    with gr.Column(scale=1):
                        input_image = gr.Image(label="ä¸Šä¼ è¾“å…¥å›¾åƒ", type="pil")
                        
                        with gr.Row():
                            prompt_img2img = gr.Textbox(
                                label="æç¤ºè¯ (Prompt)",
                                placeholder="æè¿°æƒ³è¦çš„é£æ ¼å˜åŒ–ï¼Œä¾‹å¦‚ï¼šoil painting style, vibrant colors",
                                lines=3,
                                scale=4
                            )
                            with gr.Column(scale=1):
                                apply_positive_to_img2img = gr.Button("â• æ­£é¢è¯æ¡", variant="secondary", size="sm")
                                apply_negative_to_img2img = gr.Button("â– è´Ÿé¢è¯æ¡", variant="secondary", size="sm")
                        
                        negative_prompt_img2img = gr.Textbox(
                            label="è´Ÿé¢æç¤ºè¯ (Negative Prompt)",
                            placeholder="ä¸æƒ³è¦çš„å…ƒç´ ",
                            lines=2
                        )
                        
                        strength = gr.Slider(0.1, 1.0, value=0.7, step=0.1, label="å˜åŒ–å¼ºåº¦ (è¶Šé«˜å˜åŒ–è¶Šå¤§)")
                        
                        with gr.Row():
                            num_steps_img2img = gr.Slider(10, 50, value=20, step=1, label="é‡‡æ ·æ­¥æ•°")
                            guidance_scale_img2img = gr.Slider(1, 20, value=7.5, step=0.5, label="å¼•å¯¼å¼ºåº¦")
                        
                        with gr.Row():
                            width_img2img = gr.Slider(256, 1024, value=512, step=64, label="å®½åº¦")
                            height_img2img = gr.Slider(256, 1024, value=512, step=64, label="é«˜åº¦")
                        
                        seed_img2img = gr.Number(label="éšæœºç§å­ (-1ä¸ºéšæœº)", value=-1)
                        generate_btn_img2img = gr.Button("ğŸ”„ ä¼ ç»Ÿå›¾ç”Ÿå›¾", variant="secondary")
                    
                    with gr.Column(scale=1):
                        output_image_img2img = gr.Image(label="ç”Ÿæˆçš„å›¾åƒ", type="pil")
                        output_status_img2img = gr.Textbox(label="ç”ŸæˆçŠ¶æ€")
            
            # Tab 3: ControlNetå›¾åƒå¼•å¯¼
            with gr.TabItem("ğŸ–¼ï¸ ControlNetæ¨¡å¼"):
                with gr.Row():
                    with gr.Column(scale=1):
                        control_image = gr.Image(label="ä¸Šä¼ æ§åˆ¶å›¾åƒ", type="pil")
                        
                        control_type_radio = gr.Radio(
                            choices=[(f"{info['name']} - {info['description']}", key) for key, info in CONTROLNET_TYPES.items()],
                            value="canny",
                            label="ğŸ® æ§åˆ¶ç±»å‹",
                            info="é€‰æ‹©æ§åˆ¶æ–¹å¼ï¼ˆéœ€è¦ä¸åŠ è½½çš„ControlNetç±»å‹ä¸€è‡´ï¼‰"
                        )
                        
                        with gr.Row():
                            prompt2 = gr.Textbox(
                                label="æç¤ºè¯ (Prompt)",
                                placeholder="åŸºäºä¸Šä¼ å›¾åƒçš„ç»“æ„ï¼Œæè¿°æƒ³è¦çš„é£æ ¼ï¼Œä¾‹å¦‚ï¼šoil painting style, sunset colors",
                                lines=3,
                                scale=4
                            )
                            with gr.Column(scale=1):
                                apply_positive_to_prompt2 = gr.Button("â• æ­£é¢è¯æ¡", variant="secondary", size="sm")
                                apply_negative_to_prompt2 = gr.Button("â– è´Ÿé¢è¯æ¡", variant="secondary", size="sm")
                        
                        negative_prompt2 = gr.Textbox(
                            label="è´Ÿé¢æç¤ºè¯ (Negative Prompt)",
                            placeholder="ä¸æƒ³è¦çš„å…ƒç´ ",
                            lines=2
                        )
                        
                        with gr.Row():
                            num_steps2 = gr.Slider(10, 50, value=20, step=1, label="é‡‡æ ·æ­¥æ•°")
                            guidance_scale2 = gr.Slider(1, 20, value=7.5, step=0.5, label="å¼•å¯¼å¼ºåº¦")
                        
                        controlnet_scale = gr.Slider(0.0, 2.0, value=1.0, step=0.1, label="ControlNetå¼ºåº¦")
                        
                        with gr.Row():
                            width2 = gr.Slider(256, 1024, value=512, step=64, label="å®½åº¦")
                            height2 = gr.Slider(256, 1024, value=512, step=64, label="é«˜åº¦")
                        
                        seed2 = gr.Number(label="éšæœºç§å­ (-1ä¸ºéšæœº)", value=-1)
                        generate_btn2 = gr.Button("ğŸ¨ ControlNetç”Ÿæˆ", variant="primary")
                    
                    with gr.Column(scale=1):
                        with gr.Row():
                            control_preview = gr.Image(label="æ§åˆ¶å›¾åƒé¢„è§ˆ", type="pil")
                            output_image2 = gr.Image(label="ç”Ÿæˆçš„å›¾åƒ", type="pil")
                        output_status2 = gr.Textbox(label="ç”ŸæˆçŠ¶æ€")
        
        # ç¤ºä¾‹å’Œå¯¹æ¯”è¯´æ˜
        gr.Markdown("""
        ## ğŸ’¡ ä¸‰ç§æ¨¡å¼å¯¹æ¯”ä¸ä½¿ç”¨æŒ‡å—
        
        ### ï¿½ **è¿è¡Œæ¨¡å¼è¯¦ç»†å¯¹æ¯”**
        
        | è¿è¡Œæ¨¡å¼ | å­˜å‚¨ç©ºé—´ | åˆå§‹åŒ–æ—¶é—´ | ç”Ÿæˆé€Ÿåº¦ | ç½‘ç»œè¦æ±‚ | æˆæœ¬ | æ¨èæŒ‡æ•° |
        |----------|----------|------------|----------|----------|------|----------|
        | **ğŸŒ APIæ¨¡å¼** | **0 GB** | å³æ—¶ | ä¸­ç­‰ | éœ€è¦ç½‘ç»œ | å…è´¹é¢åº¦+ä»˜è´¹ | â­â­â­â­â­ |
        | **ğŸ’» æœ¬åœ°æ¨¡å¼** | **4-10 GB** | 5-15åˆ†é’Ÿ | å¿«é€Ÿ | ä»…ä¸‹è½½æ—¶éœ€è¦ | ç¡¬ä»¶æˆæœ¬ | â­â­â­ |
        
        **ğŸ¯ æ¨¡å‹å­˜å‚¨ç©ºé—´è¯¦æƒ… (æœ¬åœ°æ¨¡å¼)ï¼š**
        - åŸºç¡€æ¨¡å‹ (SD v1.5): ~4GB
        - ControlNet æ¨¡å‹: ~1.5GB æ¯ä¸ª
        - é«˜çº§æ¨¡å‹ (SD v2.1): ~5-6GB
        - å®Œæ•´é…ç½®æ€»è®¡: **6-10GB**
        
        **ğŸ’¡ å»ºè®®ï¼š**
        - ğŸŸ¢ **å­˜å‚¨ç©ºé—´ç´§å¼ ** â†’ é€‰æ‹©APIæ¨¡å¼
        - ğŸŸ¢ **éœ€è¦é¢‘ç¹ç”Ÿæˆ** â†’ é€‰æ‹©æœ¬åœ°æ¨¡å¼  
        - ğŸŸ¢ **åˆæ¬¡ä½“éªŒ** â†’ å»ºè®®APIæ¨¡å¼
        
        ### ï¿½ğŸ” **ç”Ÿæˆæ¨¡å¼å¯¹æ¯”è¡¨**
        
        | æ¨¡å¼ | è¾“å…¥ | æ§åˆ¶æ–¹å¼ | ä¼˜åŠ¿ | é€‚ç”¨åœºæ™¯ |
        |------|------|----------|------|----------|
        | **ğŸ“ æ–‡ç”Ÿå›¾** | ä»…æ–‡æœ¬ | æç¤ºè¯ | å®Œå…¨åˆ›æ–°ï¼Œæ— é™å¯èƒ½ | åŸåˆ›ä½œå“ï¼Œæ¦‚å¿µè®¾è®¡ |
        | **ğŸ”„ ä¼ ç»Ÿå›¾ç”Ÿå›¾** | å›¾ç‰‡+æ–‡æœ¬ | strengthå‚æ•° | å¿«é€Ÿé£æ ¼è½¬æ¢ | ç®€å•é£æ ¼åŒ–ï¼Œå¿«é€Ÿä¿®æ”¹ |
        | **ğŸ–¼ï¸ ControlNet** | å›¾ç‰‡+æ–‡æœ¬ | ç²¾ç¡®ç»“æ„æ§åˆ¶ | ä¿æŒç»“æ„ï¼Œç²¾ç¡®æ§åˆ¶ | å»ºç­‘é‡è®¾è®¡ï¼Œå§¿æ€ä¿æŒ |
        
        ### ğŸ“ **æ–‡ç”Ÿå›¾æ¨¡å¼ç¤ºä¾‹ï¼š**
        - `a majestic dragon flying over a medieval castle, fantasy art, highly detailed`
        - `portrait of a young woman, oil painting style, soft lighting, renaissance art`
        
        ### ğŸ¯ **Prompt è¾…åŠ©å™¨ä½¿ç”¨è¯´æ˜ï¼š**
        - **âœ¨ æ­£é¢è¯æ¡**ï¼šæè¿°ä½ æƒ³è¦çš„æ•ˆæœã€é£æ ¼ã€è´¨é‡ç­‰
        - **ğŸš« è´Ÿé¢è¯æ¡**ï¼šæè¿°ä½ ä¸æƒ³è¦çš„é—®é¢˜ã€é£æ ¼ã€ç‘•ç–µç­‰
        - **ğŸ“ åº”ç”¨æ–¹å¼**ï¼šç‚¹å‡» "â•æ­£é¢è¯æ¡" æˆ– "â–è´Ÿé¢è¯æ¡" æŒ‰é’®ç›´æ¥æ›¿æ¢å½“å‰å†…å®¹
        - **ğŸ’¡ ä½¿ç”¨æŠ€å·§**ï¼šå…ˆé€‰æ‹©è¯æ¡ï¼Œå†ç‚¹å‡»åº”ç”¨åˆ°å¯¹åº”çš„æç¤ºè¯æ¡†ä¸­
        
        ### ğŸ”„ **ä¼ ç»Ÿå›¾ç”Ÿå›¾ vs ğŸ–¼ï¸ ControlNet è¯¦ç»†å¯¹æ¯”ï¼š**
        
        **ä¼ ç»Ÿå›¾ç”Ÿå›¾çš„é—®é¢˜ï¼š**
        - ğŸ”¸ ç»“æ„ä¸ç¨³å®šï¼šåŒæ ·å‚æ•°å¯èƒ½äº§ç”Ÿå®Œå…¨ä¸åŒç»“æœ
        - ğŸ”¸ strengthéš¾è°ƒï¼šå¤ªé«˜ä¸¢å¤±åŸå›¾ï¼Œå¤ªä½æ”¹å˜ä¸å¤Ÿ
        - ğŸ”¸ ç»†èŠ‚ä¸¢å¤±ï¼šå®¹æ˜“å¤±å»é‡è¦çš„ç»“æ„ä¿¡æ¯
        
        **ControlNetçš„ä¼˜åŠ¿ï¼š**
        - âœ… ç²¾ç¡®æ§åˆ¶ï¼šä¿ç•™è¾¹ç¼˜ã€æ·±åº¦ã€å§¿æ€ç­‰ç»“æ„ä¿¡æ¯
        - âœ… å¯é¢„æµ‹æ€§ï¼šç›¸åŒè¾“å…¥äº§ç”Ÿä¸€è‡´ç»“æœ
        - âœ… é«˜ä¿çœŸåº¦ï¼šä¿æŒåŸå›¾å…³é”®ç‰¹å¾çš„åŒæ—¶è¿›è¡Œé£æ ¼è½¬æ¢
        
        ### ğŸ› ï¸ **å‚æ•°è°ƒèŠ‚å»ºè®®ï¼š**
        - **é‡‡æ ·æ­¥æ•°**ï¼š20-30 (è´¨é‡ä¸é€Ÿåº¦å¹³è¡¡)
        - **å¼•å¯¼å¼ºåº¦**ï¼š7-12 (æ–‡æœ¬æè¿°å½±å“åŠ›)
        - **å˜åŒ–å¼ºåº¦**(ä¼ ç»Ÿå›¾ç”Ÿå›¾)ï¼š0.6-0.8 (ä¿ç•™åŸå›¾ç¨‹åº¦)
        - **ControlNetå¼ºåº¦**ï¼š0.8-1.2 (ç»“æ„æ§åˆ¶å¼ºåº¦)
        """)
        
        # ç»‘å®šäº‹ä»¶
        
        # API Token è®¾ç½®äº‹ä»¶
        def update_api_token(token):
            global HF_API_TOKEN
            HF_API_TOKEN = token.strip() if token else None
            return f"ğŸ”‘ API Token {'å·²è®¾ç½®' if token else 'æœªè®¾ç½®'}"
        
        # è¿è¡Œæ¨¡å¼åˆ‡æ¢äº‹ä»¶  
        def update_run_mode(mode):
            global RUN_MODE
            RUN_MODE = mode
            mode_text = "ğŸŒ APIæ¨¡å¼" if mode == "api" else "ğŸ’» æœ¬åœ°æ¨¡å¼"
            storage_text = "å­˜å‚¨å ç”¨: 0 GB" if mode == "api" else "å­˜å‚¨å ç”¨: 4-10 GB"
            return f"âš™ï¸ {mode_text}\nğŸ’¾ {storage_text}"
        
        api_token_input.change(
            update_api_token,
            inputs=[api_token_input],
            outputs=[]
        )
        
        run_mode_radio.change(
            update_run_mode,
            inputs=[run_mode_radio],
            outputs=[]
        )
        
        # ä»£ç†è®¾ç½®äº‹ä»¶
        def update_proxy_settings(enabled, http_proxy, https_proxy):
            status = update_proxy_config(enabled, http_proxy, https_proxy)
            return status
        
        proxy_enabled.change(
            update_proxy_settings,
            inputs=[proxy_enabled, http_proxy_input, https_proxy_input],
            outputs=[proxy_status]
        )
        
        http_proxy_input.change(
            update_proxy_settings,
            inputs=[proxy_enabled, http_proxy_input, https_proxy_input],
            outputs=[proxy_status]
        )
        
        https_proxy_input.change(
            update_proxy_settings,
            inputs=[proxy_enabled, http_proxy_input, https_proxy_input],
            outputs=[proxy_status]
        )
        
        # GitHub æ¨é€äº‹ä»¶
        push_to_github_btn.click(
            auto_push_to_github,
            inputs=[],
            outputs=[github_status]
        )
        
        # æ¨¡å‹åŠ è½½äº‹ä»¶
        load_btn.click(
            load_models, 
            inputs=[run_mode_radio, model_dropdown, controlnet_dropdown, api_token_input], 
            outputs=[load_status]
        )
        
        # æ›´æ–°å½“å‰æ¨¡å‹æ˜¾ç¤º
        model_dropdown.change(
            lambda x: f"ğŸ“¦ é€‰ä¸­æ¨¡å‹: {MODELS.get(x, x)}",
            inputs=[model_dropdown],
            outputs=[current_model_display]
        )
        
        # Prompt è¾…åŠ©å™¨äº‹ä»¶
        def get_selected_positive_tags(*tag_groups):
            """è·å–æ‰€æœ‰é€‰ä¸­çš„æ­£é¢æ ‡ç­¾"""
            selected_tags = []
            for tags in tag_groups:
                if tags:
                    selected_tags.extend(tags)
            return ", ".join(selected_tags) if selected_tags else ""
        
        def get_selected_negative_tags(*tag_groups):
            """è·å–æ‰€æœ‰é€‰ä¸­çš„è´Ÿé¢æ ‡ç­¾"""
            selected_tags = []
            for tags in tag_groups:
                if tags:
                    selected_tags.extend(tags)
            return ", ".join(selected_tags) if selected_tags else ""
        
        def clear_all_tags():
            return [[] for _ in range(14)]  # 7ä¸ªæ­£é¢tagç»„ + 7ä¸ªè´Ÿé¢tagç»„
        
        # æ­£é¢è¯æ¡åº”ç”¨åˆ°å„ä¸ªpromptæ¡†çš„äº‹ä»¶
        apply_positive_to_prompt1.click(
            get_selected_positive_tags,
            inputs=[quality_tags, style_tags, lighting_tags, composition_tags, mood_tags, scene_tags, color_tags],
            outputs=[prompt1]
        )
        
        apply_positive_to_img2img.click(
            get_selected_positive_tags,
            inputs=[quality_tags, style_tags, lighting_tags, composition_tags, mood_tags, scene_tags, color_tags],
            outputs=[prompt_img2img]
        )
        
        apply_positive_to_prompt2.click(
            get_selected_positive_tags,
            inputs=[quality_tags, style_tags, lighting_tags, composition_tags, mood_tags, scene_tags, color_tags],
            outputs=[prompt2]
        )
        
        # è´Ÿé¢è¯æ¡åº”ç”¨åˆ°å„ä¸ªnegative promptæ¡†çš„äº‹ä»¶
        apply_negative_to_prompt1.click(
            get_selected_negative_tags,
            inputs=[neg_quality_tags, neg_anatomy_tags, neg_face_tags, neg_style_tags, neg_tech_tags, neg_lighting_tags, neg_composition_tags],
            outputs=[negative_prompt1]
        )
        
        apply_negative_to_img2img.click(
            get_selected_negative_tags,
            inputs=[neg_quality_tags, neg_anatomy_tags, neg_face_tags, neg_style_tags, neg_tech_tags, neg_lighting_tags, neg_composition_tags],
            outputs=[negative_prompt_img2img]
        )
        
        apply_negative_to_prompt2.click(
            get_selected_negative_tags,
            inputs=[neg_quality_tags, neg_anatomy_tags, neg_face_tags, neg_style_tags, neg_tech_tags, neg_lighting_tags, neg_composition_tags],
            outputs=[negative_prompt2]
        )
        
        # å…¨å±€åº”ç”¨æŒ‰é’®äº‹ä»¶ï¼ˆå…¼å®¹æ€§ä¿ç•™ï¼‰
        apply_positive_tags_btn.click(
            get_selected_positive_tags,
            inputs=[quality_tags, style_tags, lighting_tags, composition_tags, mood_tags, scene_tags, color_tags],
            outputs=[]
        )
        
        apply_negative_tags_btn.click(
            get_selected_negative_tags,
            inputs=[neg_quality_tags, neg_anatomy_tags, neg_face_tags, neg_style_tags, neg_tech_tags, neg_lighting_tags, neg_composition_tags],
            outputs=[]
        )
        
        clear_tags_btn.click(
            clear_all_tags,
            outputs=[quality_tags, style_tags, lighting_tags, composition_tags, mood_tags, scene_tags, color_tags,
                    neg_quality_tags, neg_anatomy_tags, neg_face_tags, neg_style_tags, neg_tech_tags, neg_lighting_tags, neg_composition_tags]
        )
        
        # åŸæœ‰çš„ç”Ÿæˆäº‹ä»¶
        generate_btn1.click(
            generate_image,
            inputs=[prompt1, negative_prompt1, num_steps1, guidance_scale1, width1, height1, seed1],
            outputs=[output_image1, output_status1]
        )
        
        generate_btn_img2img.click(
            generate_img2img,
            inputs=[prompt_img2img, negative_prompt_img2img, input_image, strength, num_steps_img2img, guidance_scale_img2img, width_img2img, height_img2img, seed_img2img],
            outputs=[output_image_img2img, output_status_img2img]
        )
        
        generate_btn2.click(
            generate_controlnet_image,
            inputs=[prompt2, negative_prompt2, control_image, control_type_radio, num_steps2, guidance_scale2, controlnet_scale, width2, height2, seed2],
            outputs=[output_image2, control_preview, output_status2]
        )
    
    return demo

def query_hf_api(endpoint, payload, api_token=None):
    """Call Hugging Face API with proxy support"""
    headers = {"Content-Type": "application/json"}
    if api_token:
        headers["Authorization"] = f"Bearer {api_token}"
    
    # é…ç½®ä»£ç†
    proxies = {}
    if PROXY_CONFIG["enabled"]:
        if PROXY_CONFIG["http"]:
            proxies["http"] = PROXY_CONFIG["http"]
        if PROXY_CONFIG["https"]:
            proxies["https"] = PROXY_CONFIG["https"]
    
    try:
        # å¢åŠ è¶…æ—¶æ—¶é—´å¹¶ä½¿ç”¨ä»£ç†
        response = requests.post(
            endpoint, 
            headers=headers, 
            json=payload, 
            timeout=120,  # å¢åŠ åˆ°2åˆ†é’Ÿ
            proxies=proxies if proxies else None
        )
        
        if response.status_code == 200:
            return response.content
        elif response.status_code == 503:
            raise Exception("Model is loading, please try again later")
        elif response.status_code == 429:
            raise Exception("API rate limit exceeded, please try again later")
        elif response.status_code == 401:
            raise Exception("Invalid or missing API token")
        elif response.status_code == 404:
            raise Exception("Model endpoint not found")
        else:
            # Ensure error message is ASCII safe
            error_text = "Unknown API error"
            try:
                if response.text:
                    # Try to get ASCII-safe error message
                    error_text = response.text.encode('ascii', 'ignore').decode('ascii')
                    if not error_text.strip():
                        error_text = "API error with non-ASCII response"
            except:
                error_text = "API response encoding error"
            raise Exception(f"API call failed: {response.status_code}, {error_text}")
    except requests.exceptions.Timeout:
        proxy_info = f" (using proxy: {proxies})" if proxies else " (no proxy)"
        raise Exception(f"API call timeout after 120s{proxy_info}, please check network connection or proxy settings")
    except requests.exceptions.ConnectionError as e:
        proxy_info = f" (using proxy: {proxies})" if proxies else " (no proxy)"
        raise Exception(f"Network connection error{proxy_info}, please check network settings or try enabling proxy")
    except Exception as e:
        # Ensure all error messages are ASCII safe
        error_msg = str(e)
        try:
            error_msg.encode('ascii')
        except UnicodeEncodeError:
            error_msg = "API call error with encoding issues"
        raise Exception(error_msg)

def generate_image_api(prompt, negative_prompt="", model_id="runwayml/stable-diffusion-v1-5"):
    """Generate image using API"""
    endpoint = API_ENDPOINTS.get(model_id)
    if not endpoint:
        raise Exception(f"Model {model_id} does not support API mode")
    
    # Ensure prompt and negative_prompt are ASCII safe
    try:
        safe_prompt = prompt.encode('utf-8', 'ignore').decode('utf-8')
        safe_negative_prompt = negative_prompt.encode('utf-8', 'ignore').decode('utf-8') if negative_prompt else ""
    except:
        safe_prompt = "safe prompt"
        safe_negative_prompt = ""
    
    payload = {
        "inputs": safe_prompt,
        "parameters": {
            "negative_prompt": safe_negative_prompt,
            "num_inference_steps": 20,
            "guidance_scale": 7.5,
        }
    }
    
    try:
        image_bytes = query_hf_api(endpoint, payload, HF_API_TOKEN)
        image = Image.open(io.BytesIO(image_bytes))
        return image, "API image generation successful!"
    except Exception as e:
        return None, f"API generation failed: {str(e)}"

def generate_controlnet_image_api(prompt, negative_prompt, control_image, control_type):
    """Generate ControlNet image using API"""
    endpoint = CONTROLNET_API_ENDPOINTS.get(control_type)
    if not endpoint:
        raise Exception(f"ControlNet type {control_type} does not support API mode")
    
    # Convert control image to base64
    import base64
    import io
    
    buffered = io.BytesIO()
    control_image.save(buffered, format="PNG")
    control_image_b64 = base64.b64encode(buffered.getvalue()).decode()
    
    # Ensure prompt and negative_prompt are safe
    try:
        safe_prompt = prompt.encode('utf-8', 'ignore').decode('utf-8')
        safe_negative_prompt = negative_prompt.encode('utf-8', 'ignore').decode('utf-8') if negative_prompt else ""
    except:
        safe_prompt = "safe prompt"
        safe_negative_prompt = ""
    
    payload = {
        "inputs": {
            "prompt": safe_prompt,
            "image": control_image_b64,
            "negative_prompt": safe_negative_prompt
        }
    }
    
    try:
        image_bytes = query_hf_api(endpoint, payload, HF_API_TOKEN)
        image = Image.open(io.BytesIO(image_bytes))
        control_type_name = CONTROLNET_TYPES[control_type]['name']
        return image, f"API mode {control_type_name} image generation successful!"
    except Exception as e:
        return None, f"ControlNet API generation failed: {str(e)}"

def generate_img2img_api(prompt, negative_prompt, input_image, strength):
    """Generate img2img image using API"""
    # Note: Hugging Face public API has limited img2img support
    # This is a basic implementation that may need adjustment
    endpoint = API_ENDPOINTS.get("runwayml/stable-diffusion-v1-5")  # Use default model
    if not endpoint:
        raise Exception("img2img API mode not supported")
    
    # Convert input image to base64
    import base64
    import io
    
    buffered = io.BytesIO()
    input_image.save(buffered, format="PNG")
    input_image_b64 = base64.b64encode(buffered.getvalue()).decode()
    
    # Ensure prompt and negative_prompt are safe
    try:
        safe_prompt = prompt.encode('utf-8', 'ignore').decode('utf-8')
        safe_negative_prompt = negative_prompt.encode('utf-8', 'ignore').decode('utf-8') if negative_prompt else ""
    except:
        safe_prompt = "safe prompt"
        safe_negative_prompt = ""
    
    # Note: This is a simplified implementation, real img2img API may need different payload format
    payload = {
        "inputs": {
            "prompt": safe_prompt,
            "image": input_image_b64,
            "negative_prompt": safe_negative_prompt,
            "strength": strength
        }
    }
    
    try:
        # Note: Since Hugging Face public API has limited img2img support, this may fail
        # Users are recommended to use text-to-image function in API mode
        image_bytes = query_hf_api(endpoint, payload, HF_API_TOKEN)
        image = Image.open(io.BytesIO(image_bytes))
        return image, "API mode img2img image generation successful!"
    except Exception as e:
        return None, f"img2img API not supported, recommend using local mode or text-to-image function: {str(e)}"
    
    # å°†è¾“å…¥å›¾åƒè½¬æ¢ä¸ºbase64
    import base64
    import io
    
    buffered = io.BytesIO()
    input_image.save(buffered, format="PNG")
    input_image_b64 = base64.b64encode(buffered.getvalue()).decode()
    
    # æ³¨æ„ï¼šè¿™æ˜¯ä¸€ä¸ªç®€åŒ–çš„å®ç°ï¼ŒçœŸå®çš„img2img APIå¯èƒ½éœ€è¦ä¸åŒçš„payloadæ ¼å¼
    payload = {
        "inputs": {
            "prompt": prompt,
            "image": input_image_b64,
            "negative_prompt": negative_prompt if negative_prompt else "",
            "strength": strength
        }
    }
    
    try:
        # æ³¨æ„ï¼šç”±äºHugging Faceå…¬å…±APIå¯¹img2imgæ”¯æŒæœ‰é™ï¼Œè¿™é‡Œå¯èƒ½ä¼šå¤±è´¥
        # å»ºè®®ç”¨æˆ·åœ¨APIæ¨¡å¼ä¸‹ä¼˜å…ˆä½¿ç”¨æ–‡ç”Ÿå›¾åŠŸèƒ½
        image_bytes = query_hf_api(endpoint, payload, HF_API_TOKEN)
        image = Image.open(io.BytesIO(image_bytes))
        return image, "âœ… APIæ¨¡å¼ img2img å›¾åƒç”ŸæˆæˆåŠŸï¼"
    except Exception as e:
        return None, f"âŒ img2img APIæš‚ä¸æ”¯æŒï¼Œå»ºè®®ä½¿ç”¨æœ¬åœ°æ¨¡å¼æˆ–æ–‡ç”Ÿå›¾åŠŸèƒ½: {str(e)}"

if __name__ == "__main__":
    demo = create_interface()
    demo.launch(debug=True)