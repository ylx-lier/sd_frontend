"""
APIå®¢æˆ·ç«¯æ¨¡å— - å¤„ç†ä¸Hugging Face APIçš„é€šä¿¡
"""

import requests
import io
import base64
from PIL import Image
from config import API_ENDPOINTS, CONTROLNET_API_ENDPOINTS, CONTROLNET_TYPES, PROXY_CONFIG, API_SUPPORTED_MODELS

# å…¨å±€å˜é‡
HF_API_TOKEN = None

def set_api_token(token):
    """è®¾ç½®API Token"""
    global HF_API_TOKEN
    HF_API_TOKEN = token.strip() if token else None

def validate_api_key(api_token):
    """éªŒè¯API Keyçš„æœ‰æ•ˆæ€§ - æ”¹è¿›ç‰ˆæœ¬"""
    if not api_token.strip():
        return "âš ï¸ è¯·è¾“å…¥æœ‰æ•ˆçš„API Token"
    
    token = api_token.strip()
    
    # åŸºæœ¬æ ¼å¼æ£€æŸ¥
    if not token.startswith('hf_'):
        return "âŒ Tokenæ ¼å¼é”™è¯¯ï¼šåº”è¯¥ä»¥ 'hf_' å¼€å¤´"
    
    if len(token) < 30:
        return "âŒ Tokené•¿åº¦è¿‡çŸ­ï¼šè¯·æ£€æŸ¥æ˜¯å¦å®Œæ•´å¤åˆ¶"
    
    try:
        # æ„å»ºä»£ç†é…ç½®
        proxies = None
        if PROXY_CONFIG.get('enabled'):
            proxies = {}
            if PROXY_CONFIG.get('http'):
                proxies['http'] = PROXY_CONFIG['http']
            if PROXY_CONFIG.get('https'):
                proxies['https'] = PROXY_CONFIG['https']
        
        headers = {"Authorization": f"Bearer {token}"}
        
        # æ–¹æ³•1: å°è¯•è®¿é—®ç”¨æˆ·ä¿¡æ¯API (ä½¿ç”¨æ­£ç¡®çš„v2ç«¯ç‚¹)
        try:
            response = requests.get(
                "https://huggingface.co/api/whoami-v2",
                headers=headers,
                timeout=15,
                proxies=proxies
            )
            
            if response.status_code == 200:
                try:
                    user_info = response.json()
                    username = user_info.get('name', 'User')
                    return f"âœ… TokenéªŒè¯æˆåŠŸ - ç”¨æˆ·: {username}"
                except:
                    return f"âœ… TokenéªŒè¯æˆåŠŸ - APIå“åº”æ­£å¸¸"
            elif response.status_code == 401:
                return "âŒ Tokenæ— æ•ˆï¼šè¯·æ£€æŸ¥Tokenæ˜¯å¦æ­£ç¡®æˆ–å·²è¿‡æœŸ"
            elif response.status_code == 403:
                return "âš ï¸ Tokenæƒé™å—é™ï¼Œä½†å¯èƒ½å¯ç”¨äºåŸºç¡€APIè°ƒç”¨"
            else:
                # å¦‚æœwhoamiå¤±è´¥ï¼Œç»§ç»­å°è¯•å…¶ä»–éªŒè¯æ–¹æ³•
                pass
                 
        except requests.exceptions.RequestException:
            # whoami APIå¤±è´¥ï¼Œå°è¯•å…¶ä»–æ–¹æ³•
            pass
        
        # æ–¹æ³•2: å°è¯•è®¿é—®æ¨¡å‹åˆ—è¡¨APIï¼ˆæ›´å®½æ¾çš„éªŒè¯ï¼‰
        try:
            response = requests.get(
                "https://huggingface.co/api/models",
                headers=headers,
                timeout=15,
                proxies=proxies,
                params={"limit": 1}  # åªè¯·æ±‚1ä¸ªæ¨¡å‹ï¼Œå‡å°‘æµé‡
            )
            
            if response.status_code == 200:
                return f"âœ… TokenåŸºæœ¬æœ‰æ•ˆ - å¯è®¿é—®æ¨¡å‹API"
            elif response.status_code == 401:
                return "âŒ Tokenæ— æ•ˆæˆ–å·²è¿‡æœŸ"
            elif response.status_code == 403:
                return "âš ï¸ Tokenæƒé™ä¸è¶³ï¼Œä½†æ ¼å¼æ­£ç¡®"
            else:
                return f"âš ï¸ APIè¿”å›çŠ¶æ€ {response.status_code}ï¼Œè¯·æ£€æŸ¥Tokenæƒé™"
                
        except requests.exceptions.RequestException:
            pass
        
        # æ–¹æ³•3: æœ€åå°è¯•ç®€å•çš„æ¨ç†APIæ£€æŸ¥ï¼ˆHEADè¯·æ±‚ï¼‰
        try:
            test_endpoint = "https://api-inference.huggingface.co/models/runwayml/stable-diffusion-v1-5"
            response = requests.head(
                test_endpoint,
                headers=headers,
                timeout=10,
                proxies=proxies
            )
            
            if response.status_code in [200, 503]:  # 503è¡¨ç¤ºæ¨¡å‹åœ¨åŠ è½½
                return f"âœ… Tokenå¯ç”¨äºæ¨ç†API"
            elif response.status_code == 401:
                return "âŒ Tokenæ— æ•ˆï¼Œæ— æ³•è®¿é—®æ¨ç†API"
            elif response.status_code == 403:
                return "âŒ Tokenæƒé™ä¸è¶³ï¼Œæ— æ³•è®¿é—®æ¨ç†API"
            else:
                return f"âš ï¸ æ¨ç†APIè¿”å›çŠ¶æ€ {response.status_code}ï¼ŒTokenå¯èƒ½æœ‰æ•ˆ"
                
        except requests.exceptions.Timeout:
            return f"âš ï¸ ç½‘ç»œè¶…æ—¶ï¼ŒTokenæ ¼å¼æ­£ç¡®ä½†æ— æ³•éªŒè¯è¿æ¥"
        except requests.exceptions.ConnectionError:
            return f"âš ï¸ ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®æˆ–ä»£ç†é…ç½®"
            
    except Exception as e:
        return f"âŒ éªŒè¯è¿‡ç¨‹å‡ºé”™: {str(e)[:50]}..."
    
    # å¦‚æœæ‰€æœ‰APIè°ƒç”¨éƒ½å¤±è´¥ï¼Œä½†Tokenæ ¼å¼æ­£ç¡®
    return f"âš ï¸ æ— æ³•éªŒè¯Tokenæœ‰æ•ˆæ€§ï¼Œä½†æ ¼å¼æ­£ç¡®ã€‚å¯èƒ½æ˜¯ç½‘ç»œé—®é¢˜æˆ–APIæœåŠ¡å¼‚å¸¸"

def check_model_api_support(model_id, run_mode):
    """æ£€æŸ¥æ¨¡å‹æ˜¯å¦æ”¯æŒAPIæ¨¡å¼"""
    if run_mode != "api":
        return f"âœ… æœ¬åœ°æ¨¡å¼ - æ”¯æŒæ‰€æœ‰æ¨¡å‹"
    
    if model_id in API_ENDPOINTS:
        from config import MODELS
        return f"âœ… APIæ¨¡å¼æ”¯æŒ - {MODELS.get(model_id, model_id)}"
    else:
        available_models = ", ".join([API_SUPPORTED_MODELS.get(m, m) for m in API_ENDPOINTS.keys()])
        return f"âŒ APIæ¨¡å¼ä¸æ”¯æŒæ­¤æ¨¡å‹\nğŸ’¡ æ”¯æŒçš„æ¨¡å‹: {available_models}"

def test_model_api_connection(model_id, api_token):
    """æµ‹è¯•æ¨¡å‹APIè¿æ¥ - æ”¹è¿›ç‰ˆæœ¬"""
    if not api_token.strip():
        return "âš ï¸ è¯·å…ˆè¾“å…¥æœ‰æ•ˆçš„API Token"
    
    if model_id not in API_ENDPOINTS:
        return f"âŒ æ¨¡å‹ {model_id} ä¸æ”¯æŒAPIæ¨¡å¼"
    
    try:
        endpoint = API_ENDPOINTS[model_id]
        headers = {"Authorization": f"Bearer {api_token.strip()}"}
        
        # æ„å»ºä»£ç†é…ç½®
        proxies = None
        if PROXY_CONFIG.get('enabled'):
            proxies = {}
            if PROXY_CONFIG.get('http'):
                proxies['http'] = PROXY_CONFIG['http']
            if PROXY_CONFIG.get('https'):
                proxies['https'] = PROXY_CONFIG['https']
        
        # ä½¿ç”¨HEADè¯·æ±‚æ£€æŸ¥APIå¯è®¿é—®æ€§ï¼ˆä¸å®é™…ç”Ÿæˆå›¾ç‰‡ï¼‰
        response = requests.head(
            endpoint,
            headers=headers,
            timeout=10,
            proxies=proxies
        )
        
        from config import MODELS
        model_name = MODELS.get(model_id, model_id)
        
        if response.status_code == 200:
            return f"âœ… æ¨¡å‹APIè¿æ¥æˆåŠŸ - {model_name} å¯ç”¨"
        elif response.status_code == 503:
            return f"âš ï¸ æ¨¡å‹æ­£åœ¨åŠ è½½ä¸­ - {model_name} (è¯·ç¨åé‡è¯•)"
        elif response.status_code == 401:
            return "âŒ API Tokenæ— æ•ˆæˆ–æ— æƒé™è®¿é—®æ­¤æ¨¡å‹"
        elif response.status_code == 403:
            return "âŒ Tokenæƒé™ä¸è¶³ï¼Œæ— æ³•è®¿é—®æ¨ç†API"
        elif response.status_code == 404:
            return f"âŒ æ¨¡å‹ç«¯ç‚¹ä¸å­˜åœ¨ - {model_name}"
        elif response.status_code == 429:
            return f"âš ï¸ APIè°ƒç”¨é¢‘ç‡é™åˆ¶ - {model_name} (Tokenæœ‰æ•ˆ)"
        else:
            return f"âš ï¸ APIè¿”å›çŠ¶æ€ç  {response.status_code} - è¿æ¥å¯èƒ½æœ‰é—®é¢˜"
    
    except requests.exceptions.Timeout:
        return f"âŒ è¿æ¥è¶…æ—¶ - è¯·æ£€æŸ¥ç½‘ç»œæˆ–å¯ç”¨ä»£ç†"
    except requests.exceptions.ConnectionError:
        return f"âŒ ç½‘ç»œè¿æ¥å¤±è´¥ - è¯·æ£€æŸ¥ç½‘ç»œè®¾ç½®æˆ–ä»£ç†é…ç½®"
    except Exception as e:
        return f"âŒ è¿æ¥æµ‹è¯•å¤±è´¥: {str(e)[:50]}..."

def query_hf_api(endpoint, payload, api_token=None):
    """Call Hugging Face API with proxy support"""
    headers = {"Content-Type": "application/json"}
    if api_token:
        headers["Authorization"] = f"Bearer {api_token}"
    
    # é…ç½®ä»£ç†
    proxies = {}
    if PROXY_CONFIG["enabled"]:
        if PROXY_CONFIG["http"]:
            proxies["http"] = PROXY_CONFIG["http"]
        if PROXY_CONFIG["https"]:
            proxies["https"] = PROXY_CONFIG["https"]
    
    try:
        # å¢åŠ è¶…æ—¶æ—¶é—´å¹¶ä½¿ç”¨ä»£ç†
        response = requests.post(
            endpoint, 
            headers=headers, 
            json=payload, 
            timeout=120,  # å¢åŠ åˆ°2åˆ†é’Ÿ
            proxies=proxies if proxies else None
        )
        
        if response.status_code == 200:
            return response.content
        elif response.status_code == 503:
            raise Exception("Model is loading, please try again later")
        elif response.status_code == 429:
            raise Exception("API rate limit exceeded, please try again later")
        elif response.status_code == 401:
            raise Exception("Invalid or missing API token")
        elif response.status_code == 404:
            raise Exception("Model endpoint not found")
        else:
            # Ensure error message is ASCII safe
            error_text = "Unknown API error"
            try:
                if response.text:
                    # Try to get ASCII-safe error message
                    error_text = response.text.encode('ascii', 'ignore').decode('ascii')
                    if not error_text.strip():
                        error_text = "API error with non-ASCII response"
            except:
                error_text = "API response encoding error"
            raise Exception(f"API call failed: {response.status_code}, {error_text}")
    except requests.exceptions.Timeout:
        proxy_info = f" (using proxy: {proxies})" if proxies else " (no proxy)"
        raise Exception(f"API call timeout after 120s{proxy_info}, please check network connection or proxy settings")
    except requests.exceptions.ConnectionError as e:
        proxy_info = f" (using proxy: {proxies})" if proxies else " (no proxy)"
        raise Exception(f"Network connection error{proxy_info}, please check network settings or try enabling proxy")
    except Exception as e:
        # Ensure all error messages are ASCII safe
        error_msg = str(e)
        try:
            error_msg.encode('ascii')
        except UnicodeEncodeError:
            error_msg = "API call error with encoding issues"
        raise Exception(error_msg)

def generate_image_api(prompt, negative_prompt="", model_id="runwayml/stable-diffusion-v1-5"):
    """Generate image using API"""
    endpoint = API_ENDPOINTS.get(model_id)
    if not endpoint:
        raise Exception(f"Model {model_id} does not support API mode")
    
    # Ensure prompt and negative_prompt are ASCII safe
    try:
        safe_prompt = prompt.encode('utf-8', 'ignore').decode('utf-8')
        safe_negative_prompt = negative_prompt.encode('utf-8', 'ignore').decode('utf-8') if negative_prompt else ""
    except:
        safe_prompt = "safe prompt"
        safe_negative_prompt = ""
    
    payload = {
        "inputs": safe_prompt,
        "parameters": {
            "negative_prompt": safe_negative_prompt,
            "num_inference_steps": 20,
            "guidance_scale": 7.5,
        }
    }
    
    try:
        image_bytes = query_hf_api(endpoint, payload, HF_API_TOKEN)
        image = Image.open(io.BytesIO(image_bytes))
        return image, "API image generation successful!"
    except Exception as e:
        return None, f"API generation failed: {str(e)}"

def generate_controlnet_image_api(prompt, negative_prompt, control_image, control_type):
    """Generate ControlNet image using API"""
    endpoint = CONTROLNET_API_ENDPOINTS.get(control_type)
    if not endpoint:
        raise Exception(f"ControlNet type {control_type} does not support API mode")
    
    # Convert control image to base64
    buffered = io.BytesIO()
    control_image.save(buffered, format="PNG")
    control_image_b64 = base64.b64encode(buffered.getvalue()).decode()
    
    # Ensure prompt and negative_prompt are safe
    try:
        safe_prompt = prompt.encode('utf-8', 'ignore').decode('utf-8')
        safe_negative_prompt = negative_prompt.encode('utf-8', 'ignore').decode('utf-8') if negative_prompt else ""
    except:
        safe_prompt = "safe prompt"
        safe_negative_prompt = ""
    
    payload = {
        "inputs": {
            "prompt": safe_prompt,
            "image": control_image_b64,
            "negative_prompt": safe_negative_prompt
        }
    }
    
    try:
        image_bytes = query_hf_api(endpoint, payload, HF_API_TOKEN)
        image = Image.open(io.BytesIO(image_bytes))
        control_type_name = CONTROLNET_TYPES[control_type]['name']
        return image, f"API mode {control_type_name} image generation successful!"
    except Exception as e:
        return None, f"ControlNet API generation failed: {str(e)}"

def generate_img2img_api(prompt, negative_prompt, input_image, strength):
    """Generate img2img image using API"""
    # Note: Hugging Face public API has limited img2img support
    # This is a basic implementation that may need adjustment
    endpoint = API_ENDPOINTS.get("runwayml/stable-diffusion-v1-5")  # Use default model
    if not endpoint:
        raise Exception("img2img API mode not supported")
    
    # Convert input image to base64
    buffered = io.BytesIO()
    input_image.save(buffered, format="PNG")
    input_image_b64 = base64.b64encode(buffered.getvalue()).decode()
    
    # Ensure prompt and negative_prompt are safe
    try:
        safe_prompt = prompt.encode('utf-8', 'ignore').decode('utf-8')
        safe_negative_prompt = negative_prompt.encode('utf-8', 'ignore').decode('utf-8') if negative_prompt else ""
    except:
        safe_prompt = "safe prompt"
        safe_negative_prompt = ""
    
    payload = {
        "inputs": {
            "prompt": safe_prompt,
            "image": input_image_b64,
            "negative_prompt": safe_negative_prompt,
            "strength": strength
        }
    }
    
    try:
        image_bytes = query_hf_api(endpoint, payload, HF_API_TOKEN)
        image = Image.open(io.BytesIO(image_bytes))
        return image, "API mode img2img generation successful!"
    except Exception as e:
        return None, f"img2img API generation failed: {str(e)}"
